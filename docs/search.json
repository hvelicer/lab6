[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "Lab 6: ML Workflows",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\n\n\n\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n\n\n\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \ncamels &lt;- power_full_join(camels ,by = 'gauge_id')"
  },
  {
    "objectID": "lab6.html#setting-up-the-lab",
    "href": "lab6.html#setting-up-the-lab",
    "title": "Lab 6: ML Workflows",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\n\n\n\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n\n\n\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \ncamels &lt;- power_full_join(camels ,by = 'gauge_id')"
  },
  {
    "objectID": "lab6.html#question-1",
    "href": "lab6.html#question-1",
    "title": "Lab 6: ML Workflows",
    "section": "Question 1",
    "text": "Question 1\nzero_q_freq represents the frequency of days where Q = 0 mm/day (as a %). The Q variable represents daily discharge.\n\nExploratory Data Analysis\n\nlibrary(ggpubr)\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()"
  },
  {
    "objectID": "lab6.html#question-2",
    "href": "lab6.html#question-2",
    "title": "Lab 6: ML Workflows",
    "section": "Question 2",
    "text": "Question 2\n\nMaps of the sites\n\nplot1 &lt;- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = aridity)) +\n  scale_color_gradient(low = \"orange\", high = \"dodgerblue\") +\n  labs(x = \"Longitude\", y = \"Latitude\", title = \"Aridity Across the US\") +\n  ggthemes::theme_map()\n\nplot2 &lt;- p2 &lt;- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = p_mean)) +\n  scale_color_gradient(low = \"green\", high = \"purple\") +\n  labs(x = \"Longitude\", y = \"Latitude\", title = \"Mean Daily Precipitation Across the US\" ) + \n  ggthemes::theme_map()\n\nggarrange(plot1, plot2)\n\n\n\n\n\n\n\n\n\n\nModel Preparation\n\ncamels %&gt;%\n  select(aridity, p_mean, q_mean) %&gt;%\n  drop_na() %&gt;% \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\n\nVisual EDA\n\n# XY plot of aridity and rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  scale_color_viridis_c() +\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Testing a transformation\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Visualize how log transform benefits the q_mean data\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nModel Building\n\n# Splitting the data\nset.seed(123)\n\ncamels &lt;- camels %&gt;% \n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n# Preprocessor: recipe\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) %&gt;%\n  step_naomit(all_predictors(), all_outcomes())\n\n# Naive base lm approach\nbaked_data &lt;- prep(rec, camels_train) %&gt;% \n  bake(new_data = NULL)\n\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n# Correct Version: prep -&gt; bake -&gt; predict\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\n\n\nModel Evaluation: Statistical and Visual\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n# Linear model\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n# Workflow\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_model) %&gt;%\n  fit(data = camels_train) \n\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n# Making predictions\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\n# Scatter plot \nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n# Switching it up\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_model) %&gt;%\n  fit(data = camels_train) \n\n# Predictions\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\n# Scatter plot pt. 2\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.592\n2 rsq     standard       0.736\n3 mae     standard       0.367\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n# Workflowset approach\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     1\n2 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     1\n3 recipe_rand_fore… Prepro… rmse    0.565  0.0249    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.769  0.0261    10 recipe       rand…     2"
  },
  {
    "objectID": "lab6.html#question-3",
    "href": "lab6.html#question-3",
    "title": "Lab 6: ML Workflows",
    "section": "Question 3",
    "text": "Question 3\n\nBuild a xgboost (engine) regression (mode) model using boost_tree\n\nxgb_mod &lt;- boost_tree(mode = \"regression\",\n                      trees = 1000) %&gt;%\n  set_engine('xgboost')\n\n\n\nBuild a neural network model using the nnet engine from the baguette package using the bag_mlp function\n\nnn_mod &lt;- bag_mlp() %&gt;%\n  set_engine('nnet') %&gt;%\n  set_mode(\"regression\")\n\n# Adding to the above workflow\nxgb_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(xgb_mod) %&gt;%\n  fit(data = camels_train) %&gt;%\n  augment(camels_train)\n  \nnn_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(nn_mod) %&gt;%\n  fit(data = camels_train) %&gt;%\n  augment(camels_train)\n\n\n\nEvaluate the model and compare it to the linear and random forest models\n\nmetrics(xgb_wf, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     0.00292\n2 rsq     standard     1.00   \n3 mae     standard     0.00211\n\nmetrics(nn_wf, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.478\n2 rsq     standard       0.837\n3 mae     standard       0.299\n\nplot1 &lt;- ggplot(xgb_wf, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  labs(title = \"Boosted Tree Model\") +\n  theme_linedraw()\n\nplot2 &lt;- ggplot(nn_wf, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  labs(title = \"Neural Network Model\") +\n  theme_linedraw()\n\nggarrange(plot1, plot2)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAs shown in the above plots, the boosted tree model and neural network model produced different results. This is similar to the previous evaluations on the linear regression model and random forest model which also produced different results. I would move forward with the boosted tree model because its results are directly on the 1:1 line."
  },
  {
    "objectID": "lab6.html#question-4-build-your-own",
    "href": "lab6.html#question-4-build-your-own",
    "title": "Lab 6: ML Workflows",
    "section": "Question 4 (Build Your Own)",
    "text": "Question 4 (Build Your Own)\n\nData Splitting\n\n# Set a seed for reproducible\nset.seed(123456)\n\n# Create an initial split with 75% used for training and 25% for testing\nsplit &lt;- initial_split(camels, prop = 0.75)\n\n# Extract your training and testing sets\ntrain_camels &lt;- training(split)\nglimpse(train_camels)\n\nRows: 503\nColumns: 59\n$ gauge_id             &lt;chr&gt; \"01548500\", \"03357350\", \"01451800\", \"02118500\", \"…\n$ p_mean               &lt;dbl&gt; 3.153346, 3.220156, 3.503207, 3.497721, 3.508962,…\n$ pet_mean             &lt;dbl&gt; 2.271782, 2.529923, 2.418851, 2.854343, 2.566778,…\n$ p_seasonality        &lt;dbl&gt; 0.17916389, 0.19294173, 0.10670771, 0.06450132, 0…\n$ frac_snow            &lt;dbl&gt; 0.202088630, 0.070238198, 0.128362666, 0.04137083…\n$ aridity              &lt;dbl&gt; 0.7204355, 0.7856524, 0.6904675, 0.8160581, 0.731…\n$ high_prec_freq       &lt;dbl&gt; 18.10, 22.60, 23.80, 22.35, 21.45, 22.20, 21.55, …\n$ high_prec_dur        &lt;dbl&gt; 1.120743, 1.167959, 1.233161, 1.238227, 1.194986,…\n$ high_prec_timing     &lt;chr&gt; \"jja\", \"jja\", \"son\", \"mam\", \"mam\", \"djf\", \"mam\", …\n$ low_prec_freq        &lt;dbl&gt; 221.00, 253.55, 254.25, 250.15, 250.60, 257.35, 2…\n$ low_prec_dur         &lt;dbl&gt; 3.177570, 4.183993, 4.188633, 4.556466, 4.111567,…\n$ low_prec_timing      &lt;chr&gt; \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", \"son\", …\n$ geol_1st_class       &lt;chr&gt; \"Siliciclastic sedimentary rocks\", \"Mixed sedimen…\n$ glim_1st_class_frac  &lt;dbl&gt; 1.0000000, 0.9184978, 0.9971881, 1.0000000, 1.000…\n$ geol_2nd_class       &lt;chr&gt; NA, \"Carbonate sedimentary rocks\", \"Carbonate sed…\n$ glim_2nd_class_frac  &lt;dbl&gt; 0.00000000, 0.08150219, 0.00281193, 0.00000000, 0…\n$ carbonate_rocks_frac &lt;dbl&gt; 0.000000000, 0.081502189, 0.002811930, 0.00000000…\n$ geol_porostiy        &lt;dbl&gt; 0.2004, 0.1151, 0.1340, 0.0100, 0.0600, 0.1421, 0…\n$ geol_permeability    &lt;dbl&gt; -14.8083, -16.1169, -16.2182, -14.1000, -11.8000,…\n$ soil_depth_pelletier &lt;dbl&gt; 1.0295666, 41.0222222, 1.0370370, 1.0439189, 39.0…\n$ soil_depth_statsgo   &lt;dbl&gt; 1.3391110, 1.5000000, 0.8278332, 1.5000000, 1.500…\n$ soil_porosity        &lt;dbl&gt; 0.4551614, 0.4546479, 0.4528590, 0.4468136, 0.465…\n$ soil_conductivity    &lt;dbl&gt; 1.2217252, 0.9644969, 1.2430216, 0.8378938, 0.778…\n$ max_water_content    &lt;dbl&gt; 0.5712620, 0.6723718, 0.3612221, 0.6873912, 0.700…\n$ sand_frac            &lt;dbl&gt; 29.48293, 28.80686, 32.12866, 31.08818, 21.01718,…\n$ silt_frac            &lt;dbl&gt; 50.45132, 45.55663, 50.37412, 30.83003, 52.10692,…\n$ clay_frac            &lt;dbl&gt; 14.672193, 25.530649, 17.617025, 37.949064, 26.83…\n$ water_frac           &lt;dbl&gt; 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,…\n$ organic_frac         &lt;dbl&gt; 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,…\n$ other_frac           &lt;dbl&gt; 5.47929870, 0.00000000, 0.00000000, 0.00000000, 0…\n$ gauge_lat            &lt;dbl&gt; 41.52174, 39.76171, 40.66176, 36.00056, 39.07033,…\n$ gauge_lon            &lt;dbl&gt; -77.44748, -86.72945, -75.62685, -80.74556, -85.4…\n$ elev_mean            &lt;dbl&gt; 546.71, 258.64, 180.41, 336.82, 264.12, 143.69, 3…\n$ slope_mean           &lt;dbl&gt; 39.14167, 5.84999, 14.89410, 18.17467, 4.26263, 9…\n$ area_gages2          &lt;dbl&gt; 1557.05, 7.75, 135.84, 400.53, 29.72, 578.94, 822…\n$ area_geospa_fabric   &lt;dbl&gt; 1557.98, 26.11, 149.11, 400.53, 32.49, 581.79, 82…\n$ frac_forest          &lt;dbl&gt; 0.9866, 0.4476, 0.4915, 0.7055, 0.6327, 0.9846, 0…\n$ lai_max              &lt;dbl&gt; 4.7800986, 2.2913309, 2.0552600, 3.8514013, 2.880…\n$ lai_diff             &lt;dbl&gt; 4.2352819, 2.0150006, 1.7182899, 3.2155886, 2.546…\n$ gvf_max              &lt;dbl&gt; 0.8767588, 0.7345496, 0.6913127, 0.8151227, 0.784…\n$ gvf_diff             &lt;dbl&gt; 0.5085068, 0.4967552, 0.4217009, 0.4135953, 0.500…\n$ dom_land_cover_frac  &lt;dbl&gt; 0.8623825, 0.6360405, 0.9931744, 0.6948508, 1.000…\n$ dom_land_cover       &lt;chr&gt; \"    Deciduous Broadleaf Forest\", \"    Croplands\"…\n$ root_depth_50        &lt;dbl&gt; 0.1886238, 0.1800000, 0.1800683, 0.1901779, 0.180…\n$ root_depth_99        &lt;dbl&gt; 1.931191, 1.500000, 1.503413, 1.700084, 1.500000,…\n$ q_mean               &lt;dbl&gt; 1.43544360, 1.18148202, 1.75990923, 1.13558931, 1…\n$ runoff_ratio         &lt;dbl&gt; 0.45521289, 0.36690210, 0.50237084, 0.32466552, 0…\n$ slope_fdc            &lt;dbl&gt; 1.72819889, 1.40885118, 1.58160098, 1.14100195, 0…\n$ baseflow_index       &lt;dbl&gt; 0.49416298, 0.32320194, 0.47715838, 0.65134520, 0…\n$ stream_elas          &lt;dbl&gt; 1.1072080, 1.5561283, 1.5483972, 2.4535915, 0.523…\n$ q5                   &lt;dbl&gt; 0.0848496063, 0.0000000000, 0.1354405779, 0.24433…\n$ q95                  &lt;dbl&gt; 5.01241193, 4.10393317, 5.90391243, 2.82083386, 5…\n$ high_q_freq          &lt;dbl&gt; 8.90, 24.65, 10.00, 4.35, 40.05, 24.65, 26.30, 8.…\n$ high_q_dur           &lt;dbl&gt; 2.507042, 2.088983, 2.000000, 1.380952, 2.075130,…\n$ low_q_freq           &lt;dbl&gt; 88.70, 152.05, 73.35, 14.45, 194.85, 139.35, 150.…\n$ low_q_dur            &lt;dbl&gt; 16.425926, 17.680233, 9.168750, 7.810811, 12.8613…\n$ zero_q_freq          &lt;dbl&gt; 0.00000000, 0.10554415, 0.00000000, 0.00000000, 0…\n$ hfd_mean             &lt;dbl&gt; 162.20, 167.10, 153.50, 172.30, 168.05, 145.45, 1…\n$ logQmean             &lt;dbl&gt; 0.361473928, 0.166769599, 0.565262232, 0.12715172…\n\ntest_camels &lt;- testing(split)\nglimpse(test_camels)\n\nRows: 168\nColumns: 59\n$ gauge_id             &lt;chr&gt; \"01055000\", \"01121000\", \"01134500\", \"01139800\", \"…\n$ p_mean               &lt;dbl&gt; 3.494183, 3.719591, 3.467413, 3.303515, 3.420860,…\n$ pet_mean             &lt;dbl&gt; 2.093235, 2.301408, 2.091698, 2.127185, 2.157740,…\n$ p_seasonality        &lt;dbl&gt; 0.167229041, 0.004098324, 0.228672353, 0.22557908…\n$ frac_snow            &lt;dbl&gt; 0.30604885, 0.15422715, 0.28058209, 0.26232897, 0…\n$ aridity              &lt;dbl&gt; 0.5990628, 0.6187263, 0.6032446, 0.6439157, 0.630…\n$ high_prec_freq       &lt;dbl&gt; 19.15, 21.50, 15.85, 19.45, 19.05, 19.95, 20.40, …\n$ high_prec_dur        &lt;dbl&gt; 1.167683, 1.197772, 1.152727, 1.164671, 1.133929,…\n$ high_prec_timing     &lt;chr&gt; \"son\", \"son\", \"jja\", \"jja\", \"jja\", \"son\", \"son\", …\n$ low_prec_freq        &lt;dbl&gt; 224.85, 241.70, 201.10, 225.55, 225.15, 226.35, 2…\n$ low_prec_dur         &lt;dbl&gt; 3.378663, 3.721324, 2.842403, 3.278343, 3.315906,…\n$ low_prec_timing      &lt;chr&gt; \"mam\", \"son\", \"mam\", \"mam\", \"mam\", \"son\", \"son\", …\n$ geol_1st_class       &lt;chr&gt; \"Siliciclastic sedimentary rocks\", \"Metamorphics\"…\n$ glim_1st_class_frac  &lt;dbl&gt; 0.6808434, 1.0000000, 0.6224206, 1.0000000, 0.663…\n$ geol_2nd_class       &lt;chr&gt; \"Metamorphics\", NA, \"Acid plutonic rocks\", NA, \"C…\n$ glim_2nd_class_frac  &lt;dbl&gt; 0.1683631527, 0.0000000000, 0.3693336019, 0.00000…\n$ carbonate_rocks_frac &lt;dbl&gt; 0.000000000, 0.000000000, 0.000000000, 1.00000000…\n$ geol_porostiy        &lt;dbl&gt; 0.1455, 0.0100, 0.0109, 0.0600, 0.0273, 0.0416, 0…\n$ geol_permeability    &lt;dbl&gt; -14.3578, -14.1000, -14.1198, -11.8000, -13.3802,…\n$ soil_depth_pelletier &lt;dbl&gt; 2.1270588, 8.9622642, 4.0740741, 2.5106383, 2.106…\n$ soil_depth_statsgo   &lt;dbl&gt; 1.3696566, 1.5000000, 1.1438600, 1.2302233, 1.348…\n$ soil_porosity        &lt;dbl&gt; 0.4240259, 0.4172702, 0.4392274, 0.4358067, 0.436…\n$ soil_conductivity    &lt;dbl&gt; 2.5500013, 3.0682180, 1.7559531, 1.9362554, 1.876…\n$ max_water_content    &lt;dbl&gt; 0.5470206, 0.5655593, 0.4767668, 0.5179107, 0.566…\n$ sand_frac            &lt;dbl&gt; 53.86201, 55.81395, 42.58599, 45.31480, 44.95952,…\n$ silt_frac            &lt;dbl&gt; 34.73449, 29.27511, 43.33541, 41.82104, 41.25753,…\n$ clay_frac            &lt;dbl&gt; 10.346323, 9.166663, 12.724207, 13.098176, 13.082…\n$ water_frac           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ organic_frac         &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.000…\n$ other_frac           &lt;dbl&gt; 0.7780162, 5.7401161, 1.0960866, 0.0000000, 0.532…\n$ gauge_lat            &lt;dbl&gt; 44.64275, 41.84371, 44.51172, 44.09284, 43.71424,…\n$ gauge_lon            &lt;dbl&gt; -70.58878, -72.16897, -71.83731, -72.33565, -72.4…\n$ elev_mean            &lt;dbl&gt; 423.12, 141.54, 450.54, 518.15, 459.80, 325.71, 4…\n$ slope_mean           &lt;dbl&gt; 72.81304, 16.99385, 47.54354, 40.99895, 60.29261,…\n$ area_gages2          &lt;dbl&gt; 250.64, 70.25, 195.13, 22.80, 1790.24, 106.99, 24…\n$ area_geospa_fabric   &lt;dbl&gt; 251.16, 94.70, 209.50, 24.92, 1780.65, 109.26, 24…\n$ frac_forest          &lt;dbl&gt; 0.9916, 0.9652, 0.9963, 1.0000, 0.9813, 0.9970, 0…\n$ lai_max              &lt;dbl&gt; 5.030033, 5.434685, 4.930550, 5.213126, 5.164034,…\n$ lai_diff             &lt;dbl&gt; 4.319226, 4.823193, 4.273607, 4.633122, 4.495081,…\n$ gvf_max              &lt;dbl&gt; 0.8861635, 0.9085610, 0.8862162, 0.8990329, 0.897…\n$ gvf_diff             &lt;dbl&gt; 0.4714315, 0.4976272, 0.4767941, 0.5260267, 0.492…\n$ dom_land_cover_frac  &lt;dbl&gt; 0.5242488, 0.9778111, 0.6038041, 1.0000000, 0.731…\n$ dom_land_cover       &lt;chr&gt; \"    Mixed Forests\", \"    Deciduous Broadleaf For…\n$ root_depth_50        &lt;dbl&gt; 0.2214549, 0.1913313, 0.2134887, 0.1900000, 0.196…\n$ root_depth_99        &lt;dbl&gt; 2.209700, 2.008876, 2.154840, 2.000000, 1.977670,…\n$ q_mean               &lt;dbl&gt; 2.2798975, 1.9583406, 2.0775792, 1.8116828, 1.858…\n$ runoff_ratio         &lt;dbl&gt; 0.6524836, 0.5264936, 0.5991728, 0.5484106, 0.543…\n$ slope_fdc            &lt;dbl&gt; 1.349312, 1.940049, 1.408166, 1.543569, 1.519482,…\n$ baseflow_index       &lt;dbl&gt; 0.4381317, 0.5363064, 0.4875983, 0.6071732, 0.562…\n$ stream_elas          &lt;dbl&gt; 1.3665871, 1.1660444, 1.1078746, 1.7476152, 1.729…\n$ q5                   &lt;dbl&gt; 0.185464951, 0.080101406, 0.238225467, 0.24680367…\n$ q95                  &lt;dbl&gt; 8.441584, 6.025019, 7.096611, 5.579909, 5.983057,…\n$ high_q_freq          &lt;dbl&gt; 16.25, 5.90, 9.05, 2.15, 5.80, 6.70, 9.05, 4.60, …\n$ high_q_dur           &lt;dbl&gt; 2.056962, 1.475000, 2.154762, 1.869565, 1.812500,…\n$ low_q_freq           &lt;dbl&gt; 83.60, 85.00, 46.15, 37.25, 42.00, 62.15, 73.80, …\n$ low_q_dur            &lt;dbl&gt; 8.941176, 9.883721, 6.888060, 7.163462, 10.120482…\n$ zero_q_freq          &lt;dbl&gt; 0.000000000, 0.000000000, 0.000000000, 0.00000000…\n$ hfd_mean             &lt;dbl&gt; 186.05, 156.35, 187.55, 190.20, 181.50, 174.25, 1…\n$ logQmean             &lt;dbl&gt; 0.82413048, 0.67209749, 0.73120339, 0.59425612, 0…\n\n# Build a 10-fold CV dataset as well\ncv_folds &lt;- vfold_cv(train_camels, v = 10)\n\ncv_folds\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits           id    \n   &lt;list&gt;           &lt;chr&gt; \n 1 &lt;split [452/51]&gt; Fold01\n 2 &lt;split [452/51]&gt; Fold02\n 3 &lt;split [452/51]&gt; Fold03\n 4 &lt;split [453/50]&gt; Fold04\n 5 &lt;split [453/50]&gt; Fold05\n 6 &lt;split [453/50]&gt; Fold06\n 7 &lt;split [453/50]&gt; Fold07\n 8 &lt;split [453/50]&gt; Fold08\n 9 &lt;split [453/50]&gt; Fold09\n10 &lt;split [453/50]&gt; Fold10\n\n\n\n\nRecipe\n\n# Define a formula you want to use to predict logQmean\nformula &lt;- logQmean ~ p_mean + aridity + high_prec_dur\n\n\nDescribe in words why you are choosing the formula you are. Consult the downloaded PDF for the data to help you make this decision.\nI chose to use aridity, p_mean, and high_prec_dur in my formula because I believe these three factors have significant influence on the mean daily discharge. Aridity (aridity) represents the dryness of an environment and environments that are more arid will in turn have a lower logQmean. Precipitation (p_mean) adds water to the overall discharge system, and going along with that, high_prec_dur will influence the logQmean because more precipitation means more daily discharge.\n\n# Build a recipe that you feel handles the predictors chosen well\ntrain_camels &lt;- na.omit(train_camels)\n\nrec &lt;- recipe(logQmean ~  p_mean + aridity + high_prec_dur, data = train_camels) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) %&gt;% \n  step_naomit(all_predictors(), all_outcomes()) %&gt;%\n  step_zv(all_predictors())\n\nrec_prep &lt;- prep(rec, training = train_camels)\nbaked_data &lt;- bake(rec_prep, new_data = NULL)\n\n\n\n\nDefine 3 Models\n\n# Define a random forest model using the rand_forest function. Set the engine to ranger and the mode to regression\nrf_mod2 &lt;- rand_forest() %&gt;%\n  set_engine('ranger') %&gt;%\n  set_mode(\"regression\")\n\n# Define two other models of your choice\nlm_mod2 &lt;- linear_reg() %&gt;%\n  set_engine('lm') %&gt;%\n  set_mode(\"regression\")\n\nxgb_mod2 &lt;- boost_tree() %&gt;%\n  set_engine('xgboost') %&gt;%\n  set_mode(\"regression\")\n\n\n\nWorkflow set()\n\n# With your pre-processing steps and models defined, you can now build a workflow_set object to fit and evaluate your models. This will allow you to compare the performance of different models on the same data.\n\n# Create a workflow object, add the recipe, add the model(s)\nrf_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(rf_mod2)\n\nlm_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_mod2)\n\nxgb_wf2 &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(xgb_mod2)\n\n# Fit the model to the resamples\nrf_res &lt;- fit_resamples(rf_wf2, resamples = cv_folds)\nlm_res &lt;- fit_resamples(lm_wf2, resamples = cv_folds)\nxgb_res &lt;- fit_resamples(xgb_wf2, resamples = cv_folds)\n\n\n\nEvaluation\n\n# Use autoplot and rank_results to compare the models.\nwf &lt;- workflow_set(list(rec), list(rf_mod2, lm_mod2, xgb_mod2)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.528  0.0263    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.797  0.0252    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.567  0.0266    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.773  0.0218    10 recipe       line…     2\n5 recipe_boost_tree Prepro… rmse    0.560  0.0341    10 recipe       boos…     3\n6 recipe_boost_tree Prepro… rsq     0.768  0.0336    10 recipe       boos…     3\n\n\n\nDescribe what model you think is best and why!\nI think the linear regression model (lm_mod2, in the green) is the best because it has the best ranked metrics for RMSE and the second best metrics for RSQ. It has the combined best metrics in both plots.\n\n\n\nExtract and Evaluate\n\n# Now that you found your favorite model, lets see how it does on the test data!\n\n# Build a workflow (not workflow set) with your favorite model, recipe, and training data. Use fit to fit all training data to the model\nwf_final &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_mod2) %&gt;%\n  fit(data = train_camels)\n\n# Use augment to make predictions on the test data\nwf_data_final &lt;- augment(wf_final, new_data = camels_test)\n\n# Create a plot of the observed vs predicted values with clear title, axis labels, and a compelling color scale\nggplot(wf_data_final, aes(x = .pred, y = logQmean, colour = logQmean)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, color = \"black\", linetype = \"dashed\") +\n  labs(title = \"Observed vs Predicted Values\",\n       x = \"Predicted logQmean\",\n       y = \"Observed logQmean\") +\n  scale_color_viridis_c()\n\n\n\n\n\n\n\n\n\nDescribe what you think of the results!\nLooking at the plot, the results are pretty accurate. The plotted observed vs. predicted values lie relatively close to the 1:1 line, especially towards the higher logQmean values, which means the predictions have a strong accuracy against the observed values."
  },
  {
    "objectID": "hyperparameter-tuning.html",
    "href": "hyperparameter-tuning.html",
    "title": "Lab 8: Hyperparameter Tuning",
    "section": "",
    "text": "Set Up (Data Import/Tidy/Transform)\n\n# Loading libraries\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(glue)\nlibrary(powerjoin)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# Reading in the data\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 'data/camels_attributes_v2.0.pdf')\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n# Cleaning the data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nsummary(camels)\n\n   gauge_id             p_mean          pet_mean     p_seasonality     \n Length:671         Min.   :0.6446   Min.   :1.899   Min.   :-1.43546  \n Class :character   1st Qu.:2.3731   1st Qu.:2.335   1st Qu.:-0.26352  \n Mode  :character   Median :3.2295   Median :2.688   Median : 0.08093  \n                    Mean   :3.2577   Mean   :2.787   Mean   :-0.04128  \n                    3rd Qu.:3.7835   3rd Qu.:3.146   3rd Qu.: 0.22399  \n                    Max.   :8.9369   Max.   :4.744   Max.   : 0.92202  \n                                                                       \n   frac_snow          aridity       high_prec_freq  high_prec_dur  \n Min.   :0.00000   Min.   :0.2203   Min.   : 7.90   Min.   :1.075  \n 1st Qu.:0.03514   1st Qu.:0.6957   1st Qu.:18.50   1st Qu.:1.209  \n Median :0.09793   Median :0.8551   Median :22.00   Median :1.282  \n Mean   :0.17760   Mean   :1.0565   Mean   :20.93   Mean   :1.350  \n 3rd Qu.:0.22306   3rd Qu.:1.2673   3rd Qu.:24.23   3rd Qu.:1.440  \n Max.   :0.90633   Max.   :5.2079   Max.   :32.70   Max.   :2.091  \n                                                                   \n high_prec_timing   low_prec_freq    low_prec_dur    low_prec_timing   \n Length:671         Min.   :169.9   Min.   : 2.789   Length:671        \n Class :character   1st Qu.:232.7   1st Qu.: 4.241   Class :character  \n Mode  :character   Median :255.8   Median : 4.950   Mode  :character  \n                    Mean   :254.6   Mean   : 5.954                     \n                    3rd Qu.:278.9   3rd Qu.: 6.702                     \n                    Max.   :348.7   Max.   :36.513                     \n                                                                       \n geol_1st_class     glim_1st_class_frac geol_2nd_class     glim_2nd_class_frac\n Length:671         Min.   :0.2967      Length:671         Min.   :0.000000   \n Class :character   1st Qu.:0.6083      Class :character   1st Qu.:0.002894   \n Mode  :character   Median :0.8294      Mode  :character   Median :0.136540   \n                    Mean   :0.7855                         Mean   :0.155426   \n                    3rd Qu.:0.9971                         3rd Qu.:0.266373   \n                    Max.   :1.0000                         Max.   :0.489930   \n                                                                              \n carbonate_rocks_frac geol_porostiy     geol_permeability soil_depth_pelletier\n Min.   :0.00000      Min.   :0.01000   Min.   :-16.50    Min.   : 0.2667     \n 1st Qu.:0.00000      1st Qu.:0.06767   1st Qu.:-14.77    1st Qu.: 1.0000     \n Median :0.00000      Median :0.13190   Median :-13.96    Median : 1.2283     \n Mean   :0.11874      Mean   :0.12637   Mean   :-13.89    Mean   :10.8728     \n 3rd Qu.:0.04333      3rd Qu.:0.18623   3rd Qu.:-13.00    3rd Qu.:12.8894     \n Max.   :1.00000      Max.   :0.28000   Max.   :-10.90    Max.   :50.0000     \n                      NA's   :3                                               \n soil_depth_statsgo soil_porosity    soil_conductivity max_water_content\n Min.   :0.3999     Min.   :0.3733   Min.   : 0.4469   Min.   :0.0866   \n 1st Qu.:1.1054     1st Qu.:0.4309   1st Qu.: 0.9321   1st Qu.:0.4293   \n Median :1.4577     Median :0.4422   Median : 1.3477   Median :0.5579   \n Mean   :1.2932     Mean   :0.4426   Mean   : 1.7405   Mean   :0.5280   \n 3rd Qu.:1.5000     3rd Qu.:0.4554   3rd Qu.: 1.9323   3rd Qu.:0.6450   \n Max.   :1.5000     Max.   :0.6800   Max.   :13.9557   Max.   :1.0520   \n                                                                        \n   sand_frac        silt_frac        clay_frac        water_frac     \n Min.   : 8.184   Min.   : 2.985   Min.   : 1.846   Min.   : 0.0000  \n 1st Qu.:25.437   1st Qu.:23.947   1st Qu.:13.999   1st Qu.: 0.0000  \n Median :35.269   Median :34.059   Median :18.663   Median : 0.0000  \n Mean   :36.468   Mean   :33.859   Mean   :19.886   Mean   : 0.1017  \n 3rd Qu.:44.457   3rd Qu.:43.639   3rd Qu.:25.420   3rd Qu.: 0.0000  \n Max.   :91.976   Max.   :67.775   Max.   :50.354   Max.   :19.3545  \n                                                                     \n  organic_frac       other_frac       gauge_lat       gauge_lon      \n Min.   : 0.0000   Min.   : 0.000   Min.   :27.05   Min.   :-124.39  \n 1st Qu.: 0.0000   1st Qu.: 0.000   1st Qu.:35.70   1st Qu.:-110.41  \n Median : 0.0000   Median : 1.309   Median :39.25   Median : -92.78  \n Mean   : 0.5918   Mean   : 9.825   Mean   :39.24   Mean   : -95.79  \n 3rd Qu.: 0.0000   3rd Qu.:11.737   3rd Qu.:43.21   3rd Qu.: -81.77  \n Max.   :57.8631   Max.   :99.378   Max.   :48.82   Max.   : -67.94  \n                                                                     \n   elev_mean         slope_mean        area_gages2       area_geospa_fabric\n Min.   :  10.21   Min.   :  0.8222   Min.   :    4.03   Min.   :    4.1   \n 1st Qu.: 249.67   1st Qu.:  7.4268   1st Qu.:  122.28   1st Qu.:  128.0   \n Median : 462.72   Median : 28.8016   Median :  329.68   Median :  340.7   \n Mean   : 759.42   Mean   : 46.1953   Mean   :  792.62   Mean   :  808.1   \n 3rd Qu.: 928.88   3rd Qu.: 73.1695   3rd Qu.:  794.29   3rd Qu.:  804.5   \n Max.   :3571.18   Max.   :255.6884   Max.   :25791.04   Max.   :25817.8   \n                                                                           \n  frac_forest        lai_max          lai_diff         gvf_max      \n Min.   :0.0000   Min.   :0.3671   Min.   :0.1544   Min.   :0.1843  \n 1st Qu.:0.2771   1st Qu.:1.8143   1st Qu.:1.1968   1st Qu.:0.6086  \n Median :0.8137   Median :3.3713   Median :2.3365   Median :0.7803  \n Mean   :0.6395   Mean   :3.2160   Mean   :2.4486   Mean   :0.7221  \n 3rd Qu.:0.9724   3rd Qu.:4.6963   3rd Qu.:3.7574   3rd Qu.:0.8649  \n Max.   :1.0000   Max.   :5.5821   Max.   :4.8315   Max.   :0.9157  \n                                                                    \n    gvf_diff      dom_land_cover_frac dom_land_cover     root_depth_50   \n Min.   :0.0290   Min.   :0.3145      Length:671         Min.   :0.1200  \n 1st Qu.:0.1883   1st Qu.:0.6511      Class :character   1st Qu.:0.1654  \n Median :0.3160   Median :0.8582      Mode  :character   Median :0.1800  \n Mean   :0.3227   Mean   :0.8100                         Mean   :0.1788  \n 3rd Qu.:0.4627   3rd Qu.:0.9967                         3rd Qu.:0.1900  \n Max.   :0.6522   Max.   :1.0000                         Max.   :0.2500  \n                                                         NA's   :24      \n root_depth_99       q_mean          runoff_ratio        slope_fdc     \n Min.   :1.500   Min.   :0.004553   Min.   :0.004238   Min.   :0.0000  \n 1st Qu.:1.522   1st Qu.:0.632918   1st Qu.:0.242443   1st Qu.:0.8978  \n Median :1.800   Median :1.131818   Median :0.350664   Median :1.2829  \n Mean   :1.830   Mean   :1.493967   Mean   :0.387146   Mean   :1.2372  \n 3rd Qu.:2.000   3rd Qu.:1.750901   3rd Qu.:0.506681   3rd Qu.:1.6306  \n Max.   :3.100   Max.   :9.688438   Max.   :1.362132   Max.   :2.4973  \n NA's   :24      NA's   :1          NA's   :1          NA's   :1       \n baseflow_index      stream_elas            q5                q95        \n Min.   :0.006858   Min.   :-0.6363   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.:0.397430   1st Qu.: 1.3177   1st Qu.:0.009155   1st Qu.: 2.066  \n Median :0.504923   Median : 1.7006   Median :0.081568   Median : 3.769  \n Mean   :0.491447   Mean   : 1.8322   Mean   :0.171803   Mean   : 5.057  \n 3rd Qu.:0.600345   3rd Qu.: 2.2255   3rd Qu.:0.219522   3rd Qu.: 6.288  \n Max.   :0.977556   Max.   : 6.2405   Max.   :2.424938   Max.   :31.817  \n                    NA's   :1         NA's   :1          NA's   :1       \n  high_q_freq        high_q_dur       low_q_freq       low_q_dur     \n Min.   :  0.000   Min.   : 0.000   Min.   :  0.00   Min.   :  0.00  \n 1st Qu.:  6.412   1st Qu.: 1.821   1st Qu.: 37.44   1st Qu.: 10.00  \n Median : 15.100   Median : 2.848   Median : 96.00   Median : 15.52  \n Mean   : 25.745   Mean   : 6.913   Mean   :107.62   Mean   : 22.28  \n 3rd Qu.: 35.788   3rd Qu.: 7.554   3rd Qu.:162.14   3rd Qu.: 26.91  \n Max.   :172.800   Max.   :92.559   Max.   :356.80   Max.   :209.88  \n NA's   :1         NA's   :1        NA's   :1        NA's   :1       \n  zero_q_freq         hfd_mean    \n Min.   :0.00000   Min.   :112.2  \n 1st Qu.:0.00000   1st Qu.:160.2  \n Median :0.00000   Median :173.8  \n Mean   :0.03415   Mean   :182.5  \n 3rd Qu.:0.00000   3rd Qu.:204.1  \n Max.   :0.96537   Max.   :287.8  \n NA's   :1         NA's   :1      \n\nls(camels)\n\n [1] \"area_gages2\"          \"area_geospa_fabric\"   \"aridity\"             \n [4] \"baseflow_index\"       \"carbonate_rocks_frac\" \"clay_frac\"           \n [7] \"dom_land_cover\"       \"dom_land_cover_frac\"  \"elev_mean\"           \n[10] \"frac_forest\"          \"frac_snow\"            \"gauge_id\"            \n[13] \"gauge_lat\"            \"gauge_lon\"            \"geol_1st_class\"      \n[16] \"geol_2nd_class\"       \"geol_permeability\"    \"geol_porostiy\"       \n[19] \"glim_1st_class_frac\"  \"glim_2nd_class_frac\"  \"gvf_diff\"            \n[22] \"gvf_max\"              \"hfd_mean\"             \"high_prec_dur\"       \n[25] \"high_prec_freq\"       \"high_prec_timing\"     \"high_q_dur\"          \n[28] \"high_q_freq\"          \"lai_diff\"             \"lai_max\"             \n[31] \"low_prec_dur\"         \"low_prec_freq\"        \"low_prec_timing\"     \n[34] \"low_q_dur\"            \"low_q_freq\"           \"max_water_content\"   \n[37] \"organic_frac\"         \"other_frac\"           \"p_mean\"              \n[40] \"p_seasonality\"        \"pet_mean\"             \"q_mean\"              \n[43] \"q5\"                   \"q95\"                  \"root_depth_50\"       \n[46] \"root_depth_99\"        \"runoff_ratio\"         \"sand_frac\"           \n[49] \"silt_frac\"            \"slope_fdc\"            \"slope_mean\"          \n[52] \"soil_conductivity\"    \"soil_depth_pelletier\" \"soil_depth_statsgo\"  \n[55] \"soil_porosity\"        \"stream_elas\"          \"water_frac\"          \n[58] \"zero_q_freq\"         \n\ncamels &lt;- na.omit(camels)\n\n\n\nData Splitting\n\nset.seed(123)\n\ncamels &lt;- camels %&gt;%\n  mutate(logQmean = log(q_mean))\n\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\n\n\nFeature Engineering\n\n# Recipe\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) %&gt;% \n  step_naomit(all_predictors(), all_outcomes()) \n\n\n\nResampling and Model Testing\n\n# Build resamples\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n# Build 3 candidate models\nxgb_mod &lt;- boost_tree() %&gt;% \n  set_engine(\"xgboost\") %&gt;% \n  set_mode(\"regression\")\n\ndt_mod &lt;- decision_tree() %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"regression\")\n\nrf_mod &lt;- rand_forest() %&gt;% \n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n# Test the models\nwf &lt;- workflow_set(list(rec), list(boost  = xgb_mod, \n                                  dt       = dt_mod,\n                                  ranger   = rf_mod)) %&gt;% \n  workflow_map(resamples = camels_cv,\n               metrics   = metric_set(mae, rsq, rmse))\n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 9 × 9\n  wflow_id      .config     .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_ranger Preprocess… mae     0.396  0.0196    10 recipe       rand…     1\n2 recipe_ranger Preprocess… rmse    0.594  0.0329    10 recipe       rand…     1\n3 recipe_ranger Preprocess… rsq     0.762  0.0289    10 recipe       rand…     1\n4 recipe_dt     Preprocess… mae     0.438  0.0213    10 recipe       deci…     2\n5 recipe_dt     Preprocess… rmse    0.609  0.0282    10 recipe       deci…     2\n6 recipe_dt     Preprocess… rsq     0.747  0.0270    10 recipe       deci…     2\n7 recipe_boost  Preprocess… mae     0.420  0.0152    10 recipe       boos…     3\n8 recipe_boost  Preprocess… rmse    0.645  0.0238    10 recipe       boos…     3\n9 recipe_boost  Preprocess… rsq     0.728  0.0203    10 recipe       boos…     3\n\n\n\nModel Selection\nBased on the autoplot and the ranked results, I am selecting the random forest model. This model has the lowest RMSE out of the three choices and was ranked first for all the metrics. This model has type random forest, mode regression, and engine ranger. The random forest model is simple and does well with overfitting, which is why I think it’s performing well.\n\n\n\nModel Tuning\n\n# Build a model for chosen specification\nforest &lt;- rand_forest(trees = tune(), min_n = tune()) %&gt;% \n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n# Create a workflow\nwf_forest &lt;- workflow(rec, \n                    rand_forest(mode       = \"regression\", \n                               engine     = \"ranger\", \n                               trees      = tune(), \n                               min_n      = tune()))\n\nwf_forest = workflow() |&gt;\n  add_recipe(rec) |&gt;\n  add_model(forest)\n\n# Check the tunable ranges/values\ndials &lt;- extract_parameter_set_dials(wf_forest) \ndials$object\n\n[[1]]\n# Trees (quantitative)\nRange: [1, 2000]\n\n[[2]]\nMinimal Node Size (quantitative)\nRange: [2, 40]\n\n# Define the search space\nmy.grid &lt;- dials %&gt;% \n  update(trees = trees(c(1, 2000))) %&gt;%\n  grid_latin_hypercube(size = 25)\n\nWarning: `grid_latin_hypercube()` was deprecated in dials 1.3.0.\nℹ Please use `grid_space_filling()` instead.\n\n# Tune the model\nmodel_params &lt;-  tune_grid(\n    wf_forest,\n    resamples = camels_cv,\n    grid = my.grid,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_grid(save_pred = TRUE)\n  )\n\nautoplot(model_params)\n\n\n\n\n\n\n\n\nLooking at the plot, as minimal node size increases, so does RSQ but MAE and RMSE decrease.\n\n# Check the skill of the tuned model\ntree_metrics = metric_set(rsq, rmse, mae)\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\nwf_final &lt;- finalize_workflow(wf_forest, hp_best)\n\nfinal_fit &lt;- last_fit(wf_final, camels_split, metrics = tree_metrics)\n\ncollect_metrics(final_fit)\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rsq     standard       0.805 Preprocessor1_Model1\n2 rmse    standard       0.609 Preprocessor1_Model1\n3 mae     standard       0.337 Preprocessor1_Model1\n\n\nThe estimates for RSQ, RMSE, and MAE are all standard. MAE is the lowest metric and RSQ is the highest metric, which indicates a strong correlation in the model. Low RMSE and MAE values mean there is a low prediction error.\n\nshow_best(model_params, metric = \"mae\")\n\n# A tibble: 5 × 8\n  trees min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1   380    20 mae     standard   0.381    10  0.0174 Preprocessor1_Model10\n2   185    28 mae     standard   0.381    10  0.0169 Preprocessor1_Model22\n3  1936    25 mae     standard   0.382    10  0.0176 Preprocessor1_Model11\n4  1914    26 mae     standard   0.382    10  0.0173 Preprocessor1_Model17\n5  1325    21 mae     standard   0.382    10  0.0179 Preprocessor1_Model12\n\n\nLooking at the first row of show_best, model number 10 had 380 trees and 20 min_n returned a mean MAE of 0.38.\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\n# Finalize the model\nfinal &lt;- finalize_workflow(wf_forest, hp_best)\n\n\n\nFinal Model Verification\n\nfit_final &lt;- last_fit(final, camels_split, metrics = tree_metrics)\n\ncollect_metrics(fit_final)\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rsq     standard       0.801 Preprocessor1_Model1\n2 rmse    standard       0.614 Preprocessor1_Model1\n3 mae     standard       0.339 Preprocessor1_Model1\n\n\nIt appears that the final model performs well. It returned a value of 0.80 for RSQ which indiciates a high correlation for the model. The RMSE is ~0.61 which means the model has good accuracy. Finally, the MAE is ~0.34 indiciates an overall low error for the mode. Overall, it performed better on the test data than the training data.\n\ncollect_predictions(final_fit) %&gt;% \n  ggplot(aes(x = .pred, y = logQmean)) + \n  geom_point() +\n  scale_color_viridis_c() +\n  geom_abline() + \n  geom_smooth(method = \"lm\") + \n  labs(title = \"Predicted vs. Actual Values for the Final Model\", \n       x = \"Predicted (log)\", \n       y = \"Actual (log)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Map\n\nfull_predict = fit(final, data = camels) %&gt;%\n  augment(new_data = camels) \n\nresiduals &lt;- full_predict %&gt;%\n  mutate(residuals=(.pred-logQmean)^2)\n\npredict_plot &lt;- ggplot(full_predict, aes(x = logQmean, y = .pred)) + \n  geom_point() + \n  geom_abline() +\n  geom_smooth(method = \"lm\") +\n  theme_minimal() +\n  labs(title = \"Random Forest Model\", \n       x = \"Actual (log)\", \n       y = \"Predicted (log)\")\n\nresiduals_plot &lt;- ggplot(residuals, aes(x = logQmean, y = residuals)) + \n  geom_point() + \n  geom_abline() +\n  geom_smooth(method = \"lm\") + \n  theme_minimal() +\n  labs(title = \"Random Forest Model - Residuals\", \n       x = \"Actual (Log10)\", \n       y = \"Predicted (Log10)\", subtitle = ) \n\npredict_plot + residuals_plot\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  }
]